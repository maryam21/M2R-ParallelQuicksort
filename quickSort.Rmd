---
title: "Quick sort analysis"
author: "Mariam Ahhttouche"
date: "January, 2023"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# The problem context
The aim of the activity is to develop a methodology to answer a specific question on a given dataset. 

The dataset is the set of Firstname given in France on a large period of time. 
[https://www.insee.fr/fr/statistiques/2540004](https://www.insee.fr/fr/statistiques/fichier/2540004/dpt2021_csv.zip), we choose this dataset because it is sufficiently large, you can't do the analysis by hand, the structure is simple


You need to use the _tidyverse_ for this analysis. Unzip the file _dpt2020_txt.zip_ (to get the **dpt2020.csv**). Read in R with this code. Note that you might need to install the `readr` package with the appropriate command.

```{r}
library(tidyverse)
library(corrplot)
```


## Download Raw Data from the website
```{r}
df <- read.csv("data/sama_2014-10-13/measurements_03:47.csv",header=T)
```

```{r}
df
dplyr::glimpse(df)
```
We notice in the Type column that there are empty spaces in the values so we need to fix this by trimming all strings in the dataset:

```{r}
df <- df %>% mutate_if(is.character, str_trim)
dplyr::glimpse(df)
```


```{r}
ggplot() +               
  geom_line(data = df, aes(x=Size, y=Time, color = Type))
```
We can see better the scaling of each type as we increase the size, however the measurements have very big intervals between them so the lines might not really match with the reality.

We plot the confidence intervals for Size and Type features:

```{r}
df$Size_F = as.factor(df$Size)
df$Type_F = as.factor(df$Type)
```


```{r}
with(df, plot(Time~Size_F))
with(df, plot(Time~Type_F))
```
From these confidence intervals we can not compare the different sizes since there confidence interval are interleaving. We can also see that we have a lot of outliers in Time/Type plot.


We want to see how big is the impact of the type of the quicksort run and the size of the problem, so we will feed these two variables into a linear regression model. To do that we first add new variables into the dataset that represent the three different categories of the Type column, since Type is a categorical variable.

```{r}
# Create dummy variable
df$Parallel <- ifelse(df$Type == "Parallel", 1, 0)
df$Sequential <- ifelse(df$Type == "Sequential", 1, 0)
df$Built_In <- ifelse(df$Type == "Built-in", 1, 0)
df
```
```{r}
dfNum=df[, c(1,6,7,8)]
mat.cor=cor(dfNum)
corrplot(mat.cor, type="upper")
```
If we include all three new variables in our model we will get an error since the three are perfectly collinear, so we will omit one of them which will be a reference level for the other variiables we keep. This means that the mean of Parallel and 

```{r}
reg3 = lm(Time~Type_F+Size, data=df)
summary(reg3)
anova(reg3)
```
Using a factor field will give us the same results as when we use dummy variables, however I prefer to use dummy variables since they are more easy to reason with

```{r}
reg1 = lm(Time~Size+Parallel+Sequential, data=df)
summary(reg1)
anova(reg1)
```
From the coefficients T values, we can see that the type feature is not considered as important by the model which is wrong, and this is probably due to the fact that we do not have enough data to infer relationship between time and type.

```{r}
reg0 = lm(Time ~ 1, data = df)
step(reg0, scope=Time~Size+Parallel+Sequential+Built_In, direction="forward")
```
Similarly to the previous result the model with just the Size feature is considered the best one.

```{r}
par(mfcol=c(2,2))
plot(reg1)
plot(reg1,4)
```
Although the first model has a good R square, we can see from the above plots that it's not a good model, in the cook's distance for example we have many outliers, and we can see from the Residuals vs Fitted plot that the biggest outliers happen when we have big values of Time which happens when we have a big size and that's when we have a significant difference in execution times between the different types of quicksort.


# Using New generated data

To improve the model we will need to have more data, so we start by doing the tests on two different machines, my machine and mandelbrot

```{r}
local_df <- read.csv("data/debian_2022-11-10/measurements_15_21.csv",header=T)
local_df <- local_df %>% mutate_if(is.character, str_trim)
dplyr::glimpse(local_df)
local_df
```


```{r}
ggplot() +               
  geom_line(data = new_df, aes(x=Size, y=Time, color = Type))
```


