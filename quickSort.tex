% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\title{Quick sort analysis}
\author{Mariam Ahhttouche}
\date{January, 2023}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Quick sort analysis},
  pdfauthor={Mariam Ahhttouche},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\begin{document}
\maketitle

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -- Attaching packages --------------------------------------- tidyverse 1.3.2 --v ggplot2 3.3.6      v purrr   0.3.4 
## v tibble  3.1.8      v dplyr   1.0.10
## v tidyr   1.2.1      v stringr 1.4.0 
## v readr   2.1.3      v forcats 0.5.2 -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(corrplot)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## corrplot 0.92 loaded
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(DoE.wrapper)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: FrF2
## Loading required package: DoE.base
## Loading required package: grid
## Loading required package: conf.design
## Registered S3 method overwritten by 'DoE.base':
##   method           from       
##   factorize.factor conf.design
## 
## Attaching package: 'DoE.base'
## 
## The following objects are masked from 'package:stats':
## 
##     aov, lm
## 
## The following object is masked from 'package:graphics':
## 
##     plot.design
## 
## The following object is masked from 'package:base':
## 
##     lengths
## 
## Loading required package: rsm
\end{verbatim}

\hypertarget{download-raw-data-from-the-website}{%
\subsection{Download Raw Data from the
website}\label{download-raw-data-from-the-website}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/sama\_2014{-}10{-}13/measurements\_03:47.csv"}\NormalTok{,}\AttributeTok{header=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Size        Type     Time
## 1      100  Sequential 0.000010
## 2      100    Parallel 0.004024
## 3      100    Built-in 0.000013
## 4      100  Sequential 0.000010
## 5      100    Parallel 0.004448
## 6      100    Built-in 0.000014
## 7      100  Sequential 0.000009
## 8      100    Parallel 0.003384
## 9      100    Built-in 0.000013
## 10     100  Sequential 0.000010
## 11     100    Parallel 0.003738
## 12     100    Built-in 0.000012
## 13     100  Sequential 0.000010
## 14     100    Parallel 0.003133
## 15     100    Built-in 0.000011
## 16    1000  Sequential 0.000128
## 17    1000    Parallel 0.020407
## 18    1000    Built-in 0.000209
## 19    1000  Sequential 0.000126
## 20    1000    Parallel 0.022003
## 21    1000    Built-in 0.000201
## 22    1000  Sequential 0.000128
## 23    1000    Parallel 0.016149
## 24    1000    Built-in 0.000210
## 25    1000  Sequential 0.000128
## 26    1000    Parallel 0.014594
## 27    1000    Built-in 0.000209
## 28    1000  Sequential 0.000129
## 29    1000    Parallel 0.014905
## 30    1000    Built-in 0.000210
## 31   10000  Sequential 0.001774
## 32   10000    Parallel 0.018943
## 33   10000    Built-in 0.001720
## 34   10000  Sequential 0.001698
## 35   10000    Parallel 0.016226
## 36   10000    Built-in 0.001733
## 37   10000  Sequential 0.001652
## 38   10000    Parallel 0.017348
## 39   10000    Built-in 0.001702
## 40   10000  Sequential 0.001680
## 41   10000    Parallel 0.017302
## 42   10000    Built-in 0.001726
## 43   10000  Sequential 0.001675
## 44   10000    Parallel 0.017386
## 45   10000    Built-in 0.001716
## 46  100000  Sequential 0.020040
## 47  100000    Parallel 0.050548
## 48  100000    Built-in 0.020300
## 49  100000  Sequential 0.020004
## 50  100000    Parallel 0.043119
## 51  100000    Built-in 0.020504
## 52  100000  Sequential 0.019763
## 53  100000    Parallel 0.050735
## 54  100000    Built-in 0.020439
## 55  100000  Sequential 0.019913
## 56  100000    Parallel 0.049806
## 57  100000    Built-in 0.020541
## 58  100000  Sequential 0.019726
## 59  100000    Parallel 0.044636
## 60  100000    Built-in 0.020252
## 61 1000000  Sequential 0.230648
## 62 1000000    Parallel 0.162221
## 63 1000000    Built-in 0.242869
## 64 1000000  Sequential 0.235778
## 65 1000000    Parallel 0.162137
## 66 1000000    Built-in 0.241607
## 67 1000000  Sequential 0.238383
## 68 1000000    Parallel 0.163279
## 69 1000000    Built-in 0.242786
## 70 1000000  Sequential 0.232921
## 71 1000000    Parallel 0.170237
## 72 1000000    Built-in 0.241583
## 73 1000000  Sequential 0.230096
## 74 1000000    Parallel 0.153896
## 75 1000000    Built-in 0.242492
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dplyr}\SpecialCharTok{::}\FunctionTok{glimpse}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 75
## Columns: 3
## $ Size <int> 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, ~
## $ Type <chr> " Sequential", " Parallel", " Built-in", " Sequential", " Paralle~
## $ Time <dbl> 0.000010, 0.004024, 0.000013, 0.000010, 0.004448, 0.000014, 0.000~
\end{verbatim}

We notice in the Type column that there are empty spaces in the values
so we need to fix this by trimming all strings in the dataset:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate\_if}\NormalTok{(is.character, str\_trim)}
\NormalTok{dplyr}\SpecialCharTok{::}\FunctionTok{glimpse}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 75
## Columns: 3
## $ Size <int> 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, ~
## $ Type <chr> "Sequential", "Parallel", "Built-in", "Sequential", "Parallel", "~
## $ Time <dbl> 0.000010, 0.004024, 0.000013, 0.000010, 0.004448, 0.000014, 0.000~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}               
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Size, }\AttributeTok{y=}\NormalTok{Time, }\AttributeTok{color =}\NormalTok{ Type))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-5-1.pdf}

We can see better the scaling of each type as we increase the size,
however the measurements have very big intervals between them so the
lines might not really match with the reality.

We plot the confidence intervals for Size and Type features:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\SpecialCharTok{$}\NormalTok{Size\_F }\OtherTok{=} \FunctionTok{as.factor}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Size)}
\NormalTok{df}\SpecialCharTok{$}\NormalTok{Type\_F }\OtherTok{=} \FunctionTok{as.factor}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Type)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{with}\NormalTok{(df, }\FunctionTok{plot}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size\_F))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-7-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{with}\NormalTok{(df, }\FunctionTok{plot}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Type\_F))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-7-2.pdf}

From these confidence intervals we can not compare the different sizes
since there confidence interval are interleaving. We can also see that
we have a lot of outliers in Time/Type plot.

We want to see how big is the impact of the type of the quicksort run
and the size of the problem, so we will feed these two variables into a
linear regression model. To do that we first add new variables into the
dataset that represent the three different categories of the Type
column, since Type is a categorical variable.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create dummy variable}
\NormalTok{df}\SpecialCharTok{$}\NormalTok{Parallel }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Type }\SpecialCharTok{==} \StringTok{"Parallel"}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{df}\SpecialCharTok{$}\NormalTok{Sequential }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Type }\SpecialCharTok{==} \StringTok{"Sequential"}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{df}\SpecialCharTok{$}\NormalTok{Built\_In }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{Type }\SpecialCharTok{==} \StringTok{"Built{-}in"}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Size       Type     Time  Size_F     Type_F Parallel Sequential Built_In
## 1      100 Sequential 0.000010     100 Sequential        0          1        0
## 2      100   Parallel 0.004024     100   Parallel        1          0        0
## 3      100   Built-in 0.000013     100   Built-in        0          0        1
## 4      100 Sequential 0.000010     100 Sequential        0          1        0
## 5      100   Parallel 0.004448     100   Parallel        1          0        0
## 6      100   Built-in 0.000014     100   Built-in        0          0        1
## 7      100 Sequential 0.000009     100 Sequential        0          1        0
## 8      100   Parallel 0.003384     100   Parallel        1          0        0
## 9      100   Built-in 0.000013     100   Built-in        0          0        1
## 10     100 Sequential 0.000010     100 Sequential        0          1        0
## 11     100   Parallel 0.003738     100   Parallel        1          0        0
## 12     100   Built-in 0.000012     100   Built-in        0          0        1
## 13     100 Sequential 0.000010     100 Sequential        0          1        0
## 14     100   Parallel 0.003133     100   Parallel        1          0        0
## 15     100   Built-in 0.000011     100   Built-in        0          0        1
## 16    1000 Sequential 0.000128    1000 Sequential        0          1        0
## 17    1000   Parallel 0.020407    1000   Parallel        1          0        0
## 18    1000   Built-in 0.000209    1000   Built-in        0          0        1
## 19    1000 Sequential 0.000126    1000 Sequential        0          1        0
## 20    1000   Parallel 0.022003    1000   Parallel        1          0        0
## 21    1000   Built-in 0.000201    1000   Built-in        0          0        1
## 22    1000 Sequential 0.000128    1000 Sequential        0          1        0
## 23    1000   Parallel 0.016149    1000   Parallel        1          0        0
## 24    1000   Built-in 0.000210    1000   Built-in        0          0        1
## 25    1000 Sequential 0.000128    1000 Sequential        0          1        0
## 26    1000   Parallel 0.014594    1000   Parallel        1          0        0
## 27    1000   Built-in 0.000209    1000   Built-in        0          0        1
## 28    1000 Sequential 0.000129    1000 Sequential        0          1        0
## 29    1000   Parallel 0.014905    1000   Parallel        1          0        0
## 30    1000   Built-in 0.000210    1000   Built-in        0          0        1
## 31   10000 Sequential 0.001774   10000 Sequential        0          1        0
## 32   10000   Parallel 0.018943   10000   Parallel        1          0        0
## 33   10000   Built-in 0.001720   10000   Built-in        0          0        1
## 34   10000 Sequential 0.001698   10000 Sequential        0          1        0
## 35   10000   Parallel 0.016226   10000   Parallel        1          0        0
## 36   10000   Built-in 0.001733   10000   Built-in        0          0        1
## 37   10000 Sequential 0.001652   10000 Sequential        0          1        0
## 38   10000   Parallel 0.017348   10000   Parallel        1          0        0
## 39   10000   Built-in 0.001702   10000   Built-in        0          0        1
## 40   10000 Sequential 0.001680   10000 Sequential        0          1        0
## 41   10000   Parallel 0.017302   10000   Parallel        1          0        0
## 42   10000   Built-in 0.001726   10000   Built-in        0          0        1
## 43   10000 Sequential 0.001675   10000 Sequential        0          1        0
## 44   10000   Parallel 0.017386   10000   Parallel        1          0        0
## 45   10000   Built-in 0.001716   10000   Built-in        0          0        1
## 46  100000 Sequential 0.020040  100000 Sequential        0          1        0
## 47  100000   Parallel 0.050548  100000   Parallel        1          0        0
## 48  100000   Built-in 0.020300  100000   Built-in        0          0        1
## 49  100000 Sequential 0.020004  100000 Sequential        0          1        0
## 50  100000   Parallel 0.043119  100000   Parallel        1          0        0
## 51  100000   Built-in 0.020504  100000   Built-in        0          0        1
## 52  100000 Sequential 0.019763  100000 Sequential        0          1        0
## 53  100000   Parallel 0.050735  100000   Parallel        1          0        0
## 54  100000   Built-in 0.020439  100000   Built-in        0          0        1
## 55  100000 Sequential 0.019913  100000 Sequential        0          1        0
## 56  100000   Parallel 0.049806  100000   Parallel        1          0        0
## 57  100000   Built-in 0.020541  100000   Built-in        0          0        1
## 58  100000 Sequential 0.019726  100000 Sequential        0          1        0
## 59  100000   Parallel 0.044636  100000   Parallel        1          0        0
## 60  100000   Built-in 0.020252  100000   Built-in        0          0        1
## 61 1000000 Sequential 0.230648 1000000 Sequential        0          1        0
## 62 1000000   Parallel 0.162221 1000000   Parallel        1          0        0
## 63 1000000   Built-in 0.242869 1000000   Built-in        0          0        1
## 64 1000000 Sequential 0.235778 1000000 Sequential        0          1        0
## 65 1000000   Parallel 0.162137 1000000   Parallel        1          0        0
## 66 1000000   Built-in 0.241607 1000000   Built-in        0          0        1
## 67 1000000 Sequential 0.238383 1000000 Sequential        0          1        0
## 68 1000000   Parallel 0.163279 1000000   Parallel        1          0        0
## 69 1000000   Built-in 0.242786 1000000   Built-in        0          0        1
## 70 1000000 Sequential 0.232921 1000000 Sequential        0          1        0
## 71 1000000   Parallel 0.170237 1000000   Parallel        1          0        0
## 72 1000000   Built-in 0.241583 1000000   Built-in        0          0        1
## 73 1000000 Sequential 0.230096 1000000 Sequential        0          1        0
## 74 1000000   Parallel 0.153896 1000000   Parallel        1          0        0
## 75 1000000   Built-in 0.242492 1000000   Built-in        0          0        1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfNum}\OtherTok{=}\NormalTok{df[, }\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{)]}
\NormalTok{mat.cor}\OtherTok{=}\FunctionTok{cor}\NormalTok{(dfNum)}
\FunctionTok{corrplot}\NormalTok{(mat.cor, }\AttributeTok{type=}\StringTok{"upper"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-9-1.pdf}

If we include all three new variables in our model we will get an error
since the three are perfectly collinear, so we will omit one of them
which will be a reference level for the other variiables we keep. This
means that the mean of Parallel and

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg3 }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Type\_F}\SpecialCharTok{+}\NormalTok{Size, }\AttributeTok{data=}\NormalTok{df)}
\FunctionTok{summary}\NormalTok{(reg3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm.default(formula = Time ~ Type_F + Size, data = df)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.057714 -0.006695 -0.004902  0.012074  0.028120 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(>|t|)    
## (Intercept)       6.688e-03  3.889e-03   1.720   0.0898 .  
## Type_FParallel   -3.139e-03  5.225e-03  -0.601   0.5499    
## Type_FSequential -1.865e-03  5.225e-03  -0.357   0.7221    
## Size              2.081e-07  5.460e-09  38.110   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.01847 on 71 degrees of freedom
## Multiple R-squared:  0.9534, Adjusted R-squared:  0.9514 
## F-statistic: 484.2 on 3 and 71 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(reg3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Response: Time
##           Df  Sum Sq Mean Sq   F value Pr(>F)    
## Type_F     2 0.00012 0.00006    0.1826 0.8335    
## Size       1 0.49557 0.49557 1452.3369 <2e-16 ***
## Residuals 71 0.02423 0.00034                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

Using a factor field will give us the same results as when we use dummy
variables, however I prefer to use dummy variables since they are more
easy to reason with

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg1 }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size}\SpecialCharTok{+}\NormalTok{Parallel}\SpecialCharTok{+}\NormalTok{Sequential, }\AttributeTok{data=}\NormalTok{df)}
\FunctionTok{summary}\NormalTok{(reg1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm.default(formula = Time ~ Size + Parallel + Sequential, data = df)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.057714 -0.006695 -0.004902  0.012074  0.028120 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  6.688e-03  3.889e-03   1.720   0.0898 .  
## Size         2.081e-07  5.460e-09  38.110   <2e-16 ***
## Parallel    -3.139e-03  5.225e-03  -0.601   0.5499    
## Sequential  -1.865e-03  5.225e-03  -0.357   0.7221    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.01847 on 71 degrees of freedom
## Multiple R-squared:  0.9534, Adjusted R-squared:  0.9514 
## F-statistic: 484.2 on 3 and 71 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(reg1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Response: Time
##            Df  Sum Sq Mean Sq   F value Pr(>F)    
## Size        1 0.49557 0.49557 1452.3369 <2e-16 ***
## Parallel    1 0.00008 0.00008    0.2377 0.6274    
## Sequential  1 0.00004 0.00004    0.1275 0.7221    
## Residuals  71 0.02423 0.00034                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

From the coefficients T values, we can see that the type feature is not
considered as important by the model which is wrong, and this is
probably due to the fact that we do not have enough data to infer
relationship between time and type.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg0 }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Time }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}
\FunctionTok{step}\NormalTok{(reg0, }\AttributeTok{scope=}\NormalTok{Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size}\SpecialCharTok{+}\NormalTok{Parallel}\SpecialCharTok{+}\NormalTok{Sequential}\SpecialCharTok{+}\NormalTok{Built\_In, }\AttributeTok{direction=}\StringTok{"forward"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Start:  AIC=-370.87
## Time ~ 1
## 
##              Df Sum of Sq     RSS     AIC
## + Size        1   0.49557 0.02435 -598.45
## <none>                    0.51992 -370.87
## + Built_In    1   0.00010 0.51982 -368.88
## + Parallel    1   0.00008 0.51984 -368.88
## + Sequential  1   0.00000 0.51992 -368.87
## 
## Step:  AIC=-598.45
## Time ~ Size
## 
##              Df  Sum of Sq      RSS     AIC
## <none>                     0.024352 -598.45
## + Built_In    1 1.0433e-04 0.024247 -596.77
## + Parallel    1 8.1112e-05 0.024270 -596.70
## + Sequential  1 1.4600e-06 0.024350 -596.45
\end{verbatim}

\begin{verbatim}
## 
## Call:
## lm.default(formula = Time ~ Size, data = df)
## 
## Coefficients:
## (Intercept)         Size  
##   5.020e-03    2.081e-07
\end{verbatim}

Similarly to the previous result the model with just the Size feature is
considered the best one.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg4 }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size, }\AttributeTok{data=}\NormalTok{df)}
\NormalTok{pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(reg4, }\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Size=}\DecValTok{100}\NormalTok{),}\AttributeTok{interval=}\StringTok{"prediction"}\NormalTok{)}
\NormalTok{pred}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           fit         lwr        upr
## 1 0.005040313 -0.03167998 0.04176061
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{confidence\_interval }\OtherTok{=} \FloatTok{0.04194724+0.0314921}
\NormalTok{confidence\_interval}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.07343934
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfcol=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(reg1)}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-15-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(reg1,}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-15-2.pdf}

Although the first model has a good R square, we can see from the above
plots that it's not a good model, in the cook's distance for example we
have many outliers, and we can see from the Residuals vs Fitted plot
that the biggest outliers happen when we have big values of Time which
happens when we have a big size and that's when we have a significant
difference in execution times between the different types of quicksort.

\hypertarget{using-new-generated-data}{%
\subsection{Using new generated data}\label{using-new-generated-data}}

To improve the model we will need to have more data, so we start by
doing the tests on two different machines, my machine and mandelbrot. I
start by testing on my local machine and I do three different
measurements at different times to reduce the impact of the time at
which we run the experiment

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{local\_df }\OtherTok{\textless{}{-}} \FunctionTok{list.files}\NormalTok{(}\AttributeTok{path =} \StringTok{"./data/debian\_2023{-}01{-}26/"}\NormalTok{, }\AttributeTok{pattern =} \StringTok{"*.csv"}\NormalTok{, }\AttributeTok{full.names =}\NormalTok{ T) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{map\_df}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{read\_csv}\NormalTok{(.)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 75 Columns: 3-- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): Type
## dbl (2): Size, Time
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.Rows: 75 Columns: 3-- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): Type
## dbl (2): Size, Time
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.Rows: 75 Columns: 3-- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): Type
## dbl (2): Size, Time
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{local\_df }\OtherTok{\textless{}{-}}\NormalTok{ local\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate\_if}\NormalTok{(is.character, str\_trim)}
\NormalTok{dplyr}\SpecialCharTok{::}\FunctionTok{glimpse}\NormalTok{(local\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 225
## Columns: 3
## $ Size <dbl> 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, ~
## $ Type <chr> "Sequential", "Parallel", "Built-in", "Sequential", "Parallel", "~
## $ Time <dbl> 0.000010, 0.004024, 0.000013, 0.000010, 0.004448, 0.000014, 0.000~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{local\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 225 x 3
##     Size Type           Time
##    <dbl> <chr>         <dbl>
##  1   100 Sequential 0.00001 
##  2   100 Parallel   0.00402 
##  3   100 Built-in   0.000013
##  4   100 Sequential 0.00001 
##  5   100 Parallel   0.00445 
##  6   100 Built-in   0.000014
##  7   100 Sequential 0.000009
##  8   100 Parallel   0.00338 
##  9   100 Built-in   0.000013
## 10   100 Sequential 0.00001 
## # ... with 215 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}               
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ local\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Size, }\AttributeTok{y=}\NormalTok{Time, }\AttributeTok{color =}\NormalTok{ Type))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-17-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{local\_df}\SpecialCharTok{$}\NormalTok{Size\_F }\OtherTok{=} \FunctionTok{as.factor}\NormalTok{(local\_df}\SpecialCharTok{$}\NormalTok{Size)}
\NormalTok{local\_df}\SpecialCharTok{$}\NormalTok{Type\_F }\OtherTok{=} \FunctionTok{as.factor}\NormalTok{(local\_df}\SpecialCharTok{$}\NormalTok{Type)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{with}\NormalTok{(local\_df, }\FunctionTok{plot}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size\_F))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-19-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{with}\NormalTok{(local\_df, }\FunctionTok{plot}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Type\_F))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-19-2.pdf}

The result here is pretty similar to the results of the original
experiment except we know have smaller confidence intervals since we
added more experiments, however we can see that we still have a lot of
outliers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg\_test\_local }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Time }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ local\_df)}
\FunctionTok{step}\NormalTok{(reg\_test\_local, }\AttributeTok{scope=}\NormalTok{Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size}\SpecialCharTok{+}\NormalTok{Type\_F, }\AttributeTok{direction=}\StringTok{"forward"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Start:  AIC=-1048.08
## Time ~ 1
## 
##          Df Sum of Sq     RSS     AIC
## + Size    1   2.00694 0.10809 -1715.2
## <none>                2.11503 -1048.1
## + Type_F  2   0.01226 2.10278 -1045.4
## 
## Step:  AIC=-1715.2
## Time ~ Size
## 
##          Df Sum of Sq      RSS     AIC
## + Type_F  2  0.012257 0.095831 -1738.3
## <none>                0.108088 -1715.2
## 
## Step:  AIC=-1738.29
## Time ~ Size + Type_F
\end{verbatim}

\begin{verbatim}
## 
## Call:
## lm.default(formula = Time ~ Size + Type_F, data = local_df)
## 
## Coefficients:
##      (Intercept)              Size    Type_FParallel  Type_FSequential  
##        2.121e-03         2.417e-07         1.612e-02         9.790e-04
\end{verbatim}

The resulting model is much better here since it takes into account the
type of the algorithm, and it gives the sequential type a much higher
coefficient than the parallel one, which matches the result when we have
a size of 1000000 but for smaller size the execution time is higher for
parallel than sequential or Built-in.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg\_local }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size}\SpecialCharTok{+}\NormalTok{Type\_F, }\AttributeTok{data=}\NormalTok{local\_df)}
\FunctionTok{summary}\NormalTok{(reg\_local)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm.default(formula = Time ~ Size + Type_F, data = local_df)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.106087 -0.003276 -0.002133  0.001744  0.108265 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(>|t|)    
## (Intercept)      2.121e-03  2.531e-03   0.838    0.403    
## Size             2.417e-07  3.553e-09  68.032  < 2e-16 ***
## Type_FParallel   1.612e-02  3.400e-03   4.742  3.8e-06 ***
## Type_FSequential 9.790e-04  3.400e-03   0.288    0.774    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02082 on 221 degrees of freedom
## Multiple R-squared:  0.9547, Adjusted R-squared:  0.9541 
## F-statistic:  1552 on 3 and 221 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(reg\_local)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Response: Time
##            Df  Sum Sq Mean Sq  F value    Pr(>F)    
## Size        1 2.00694 2.00694 4628.303 < 2.2e-16 ***
## Type_F      2 0.01226 0.00613   14.134 1.674e-06 ***
## Residuals 221 0.09583 0.00043                       
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

Here we see that the model rejects the sequential and built-in types
(value for this one is included in the intercept), which is probably due
to the fact that these two types have pretty close execution times in
different sizes.

We do the same thing but this time on mandelbrot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mandelbrot\_df }\OtherTok{\textless{}{-}} \FunctionTok{list.files}\NormalTok{(}\AttributeTok{path =} \StringTok{"./data/im2ag{-}mandelbrot\_2023{-}01{-}26/"}\NormalTok{, }\AttributeTok{pattern =} \StringTok{"*.csv"}\NormalTok{, }\AttributeTok{full.names =}\NormalTok{ T) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{map\_df}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{read\_csv}\NormalTok{(.)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 75 Columns: 3-- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): Type
## dbl (2): Size, Time
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.Rows: 75 Columns: 3-- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): Type
## dbl (2): Size, Time
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.Rows: 75 Columns: 3-- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): Type
## dbl (2): Size, Time
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mandelbrot\_df }\OtherTok{\textless{}{-}}\NormalTok{ mandelbrot\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate\_if}\NormalTok{(is.character, str\_trim)}
\NormalTok{dplyr}\SpecialCharTok{::}\FunctionTok{glimpse}\NormalTok{(mandelbrot\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 225
## Columns: 3
## $ Size <dbl> 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, ~
## $ Type <chr> "Sequential", "Parallel", "Built-in", "Sequential", "Parallel", "~
## $ Time <dbl> 0.000031, 0.031500, 0.000034, 0.000033, 0.021060, 0.000034, 0.000~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mandelbrot\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 225 x 3
##     Size Type           Time
##    <dbl> <chr>         <dbl>
##  1   100 Sequential 0.000031
##  2   100 Parallel   0.0315  
##  3   100 Built-in   0.000034
##  4   100 Sequential 0.000033
##  5   100 Parallel   0.0211  
##  6   100 Built-in   0.000034
##  7   100 Sequential 0.000031
##  8   100 Parallel   0.0273  
##  9   100 Built-in   0.000035
## 10   100 Sequential 0.000029
## # ... with 215 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mandelbrot\_df}\SpecialCharTok{$}\NormalTok{Size\_F }\OtherTok{=} \FunctionTok{as.factor}\NormalTok{(mandelbrot\_df}\SpecialCharTok{$}\NormalTok{Size)}
\NormalTok{mandelbrot\_df}\SpecialCharTok{$}\NormalTok{Type\_F }\OtherTok{=} \FunctionTok{as.factor}\NormalTok{(mandelbrot\_df}\SpecialCharTok{$}\NormalTok{Type)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}               
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ mandelbrot\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Size, }\AttributeTok{y=}\NormalTok{Time, }\AttributeTok{color =}\NormalTok{ Type))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-24-1.pdf}

We can see from this plot that the parallel performs way worse than in
the other machines which is weird since this machine has more cores than
the previous machines and we also made measurements at three different
times to reduce impact of the time of experiment in which we could have
the machine under heavy load.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg\_test\_mandelbrot }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Time }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ mandelbrot\_df)}
\FunctionTok{step}\NormalTok{(reg\_test\_mandelbrot, }\AttributeTok{scope=}\NormalTok{Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size}\SpecialCharTok{+}\NormalTok{Type\_F, }\AttributeTok{direction=}\StringTok{"forward"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Start:  AIC=-872.79
## Time ~ 1
## 
##          Df Sum of Sq    RSS      AIC
## + Size    1    3.3527 1.2569 -1163.18
## + Type_F  2    0.9193 3.6903  -918.84
## <none>                4.6096  -872.79
## 
## Step:  AIC=-1163.18
## Time ~ Size
## 
##          Df Sum of Sq     RSS     AIC
## + Type_F  2   0.91931 0.33757 -1455.0
## <none>                1.25688 -1163.2
## 
## Step:  AIC=-1454.97
## Time ~ Size + Type_F
\end{verbatim}

\begin{verbatim}
## 
## Call:
## lm.default(formula = Time ~ Size + Type_F, data = mandelbrot_df)
## 
## Coefficients:
##      (Intercept)              Size    Type_FParallel  Type_FSequential  
##       -7.711e-03         3.124e-07         1.346e-01        -1.929e-03
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg\_mandelbrot }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size}\SpecialCharTok{+}\NormalTok{Type\_F, }\AttributeTok{data=}\NormalTok{mandelbrot\_df)}
\FunctionTok{summary}\NormalTok{(reg\_mandelbrot)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm.default(formula = Time ~ Size + Type_F, data = mandelbrot_df)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.108021 -0.013583  0.007697  0.009639  0.119283 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(>|t|)    
## (Intercept)      -7.711e-03  4.750e-03  -1.623    0.106    
## Size              3.124e-07  6.669e-09  46.850   <2e-16 ***
## Type_FParallel    1.346e-01  6.382e-03  21.093   <2e-16 ***
## Type_FSequential -1.929e-03  6.382e-03  -0.302    0.763    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.03908 on 221 degrees of freedom
## Multiple R-squared:  0.9268, Adjusted R-squared:  0.9258 
## F-statistic: 932.3 on 3 and 221 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(reg\_mandelbrot)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Response: Time
##            Df Sum Sq Mean Sq F value    Pr(>F)    
## Size        1 3.3527  3.3527 2194.92 < 2.2e-16 ***
## Type_F      2 0.9193  0.4597  300.92 < 2.2e-16 ***
## Residuals 221 0.3376  0.0015                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

Here too the model took just the parallel type and size features as most
important but the coefficients we have for the features are quite
different so we can say that the machine in which we run the experiments
impacts the results, so we will now merge the data from both machines to
reduce the impact of the machine on the results

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merged\_df }\OtherTok{=} \FunctionTok{union}\NormalTok{(local\_df, mandelbrot\_df)}
\NormalTok{dplyr}\SpecialCharTok{::}\FunctionTok{glimpse}\NormalTok{(merged\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 410
## Columns: 5
## $ Size   <dbl> 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1000, 10~
## $ Type   <chr> "Sequential", "Parallel", "Built-in", "Parallel", "Built-in", "~
## $ Time   <dbl> 0.000010, 0.004024, 0.000013, 0.004448, 0.000014, 0.000009, 0.0~
## $ Size_F <fct> 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1000, 10~
## $ Type_F <fct> Sequential, Parallel, Built-in, Parallel, Built-in, Sequential,~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merged\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 410 x 5
##     Size Type           Time Size_F Type_F    
##    <dbl> <chr>         <dbl> <fct>  <fct>     
##  1   100 Sequential 0.00001  100    Sequential
##  2   100 Parallel   0.00402  100    Parallel  
##  3   100 Built-in   0.000013 100    Built-in  
##  4   100 Parallel   0.00445  100    Parallel  
##  5   100 Built-in   0.000014 100    Built-in  
##  6   100 Sequential 0.000009 100    Sequential
##  7   100 Parallel   0.00338  100    Parallel  
##  8   100 Parallel   0.00374  100    Parallel  
##  9   100 Built-in   0.000012 100    Built-in  
## 10   100 Parallel   0.00313  100    Parallel  
## # ... with 400 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}               
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ merged\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Size, }\AttributeTok{y=}\NormalTok{Time, }\AttributeTok{color =}\NormalTok{ Type))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-28-1.pdf}

We can see that the parallel execution has a lot of variability due to
the big difference between the two machines when it comes to the
parallel execution of the algorithm.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{with}\NormalTok{(local\_df, }\FunctionTok{plot}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size\_F))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-29-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{with}\NormalTok{(local\_df, }\FunctionTok{plot}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Type\_F))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-29-2.pdf}

We can see here that we still have a lot of outliers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg\_test\_merged }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Time }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ merged\_df)}
\FunctionTok{step}\NormalTok{(reg\_test\_merged, }\AttributeTok{scope=}\NormalTok{Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size}\SpecialCharTok{+}\NormalTok{Type\_F, }\AttributeTok{direction=}\StringTok{"forward"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Start:  AIC=-1688.43
## Time ~ 1
## 
##          Df Sum of Sq    RSS     AIC
## + Size    1    4.9898 1.6504 -2257.2
## + Type_F  2    0.4224 6.2178 -1711.4
## <none>                6.6402 -1688.4
## 
## Step:  AIC=-2257.2
## Time ~ Size
## 
##          Df Sum of Sq    RSS     AIC
## + Type_F  2   0.54988 1.1005 -2419.3
## <none>                1.6504 -2257.2
## 
## Step:  AIC=-2419.35
## Time ~ Size + Type_F
\end{verbatim}

\begin{verbatim}
## 
## Call:
## lm.default(formula = Time ~ Size + Type_F, data = merged_df)
## 
## Coefficients:
##      (Intercept)              Size    Type_FParallel  Type_FSequential  
##       -3.319e-03         2.776e-07         7.579e-02        -6.073e-04
\end{verbatim}

Here too the model takes into account the types and the size which is
good and gives the highest coefficient to the parallel type which
matches with the data in which the parallel algorithm has very different
execution times compared to sequential and built-in types.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg\_merged }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size}\SpecialCharTok{+}\NormalTok{Type\_F, }\AttributeTok{data=}\NormalTok{merged\_df)}
\FunctionTok{summary}\NormalTok{(reg\_merged)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm.default(formula = Time ~ Size + Type_F, data = merged_df)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.196137 -0.031491  0.003311  0.004492  0.208604 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(>|t|)    
## (Intercept)      -3.319e-03  4.830e-03  -0.687    0.492    
## Size              2.776e-07  6.388e-09  43.449   <2e-16 ***
## Type_FParallel    7.579e-02  6.229e-03  12.167   <2e-16 ***
## Type_FSequential -6.073e-04  6.458e-03  -0.094    0.925    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.05206 on 406 degrees of freedom
## Multiple R-squared:  0.8343, Adjusted R-squared:  0.833 
## F-statistic: 681.2 on 3 and 406 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(reg\_merged)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Response: Time
##            Df Sum Sq Mean Sq F value    Pr(>F)    
## Size        1 4.9898  4.9898 1840.79 < 2.2e-16 ***
## Type_F      2 0.5499  0.2749  101.43 < 2.2e-16 ***
## Residuals 406 1.1005  0.0027                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

The R squared is good but is less than the previous models' which is
probably due to the merged data having higher variability so more
unexplained parts by the model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(reg\_merged, }\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Size=}\DecValTok{300000}\NormalTok{, }\AttributeTok{Type\_F=}\StringTok{"Parallel"}\NormalTok{),}\AttributeTok{interval=}\StringTok{"prediction"}\NormalTok{)}
\NormalTok{pred}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        fit        lwr       upr
## 1 0.155741 0.05304653 0.2584356
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merged\_confidence }\OtherTok{=} \FloatTok{0.1752284+0.0302271}
\NormalTok{merged\_confidence}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2054555
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{confidence\_interval}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.07343934
\end{verbatim}

Although we used more data to fit this model we still got a higher
confidence interval than the model fitted with the original dataset
which could be explained by the high variability of the data we have
now.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfcol=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(reg\_merged)}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-35-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(reg\_merged, }\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-35-2.pdf}

We see can from the cook's distance plot that there are a lot of
outliers in the data which will result in a higher variance which makes
it harder to fit a good model. We can also see from the residuals plot
that the higher the execution time the higher the error which mostly
happens when we have bigger sizes and this is were there are big
differences between results depending on the type of the algorithm.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{size\_pred }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{100}\NormalTok{,}\DecValTok{1000000}\NormalTok{,}\AttributeTok{by=}\DecValTok{5000}\NormalTok{)}
\NormalTok{type\_pred }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{), }\FunctionTok{length}\NormalTok{(size\_pred))}

\NormalTok{par\_time\_pred }\OtherTok{\textless{}{-}}\NormalTok{ reg\_merged}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{+}\NormalTok{reg\_merged}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{2}\NormalTok{]}\SpecialCharTok{*}\NormalTok{size\_pred}\SpecialCharTok{+}\NormalTok{reg\_merged}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{3}\NormalTok{]}
\NormalTok{seq\_time\_pred }\OtherTok{\textless{}{-}}\NormalTok{ reg\_merged}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{+}\NormalTok{reg\_merged}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{2}\NormalTok{]}\SpecialCharTok{*}\NormalTok{size\_pred}\SpecialCharTok{+}\NormalTok{reg\_merged}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{4}\NormalTok{]}
\NormalTok{builtin\_time\_pred }\OtherTok{\textless{}{-}}\NormalTok{ reg\_merged}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{+}\NormalTok{reg\_merged}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{2}\NormalTok{]}\SpecialCharTok{*}\NormalTok{size\_pred}

\NormalTok{par\_fct\_reg }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{size\_pred=}\NormalTok{size\_pred, }\AttributeTok{time\_pred=}\NormalTok{par\_time\_pred)}
\NormalTok{seq\_fct\_reg }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{size\_pred=}\NormalTok{size\_pred, }\AttributeTok{type\_pred=}\NormalTok{type\_pred, }\AttributeTok{time\_pred=}\NormalTok{seq\_time\_pred)}
\NormalTok{builtin\_fct\_reg }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{size\_pred=}\NormalTok{size\_pred, }\AttributeTok{type\_pred=}\NormalTok{type\_pred, }\AttributeTok{time\_pred=}\NormalTok{builtin\_time\_pred)}

\FunctionTok{ggplot}\NormalTok{()}\SpecialCharTok{+}
\FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data=}\NormalTok{merged\_df,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Size,}\AttributeTok{y=}\NormalTok{Time, }\AttributeTok{color =}\NormalTok{ Type))}\SpecialCharTok{+} \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data=}\NormalTok{par\_fct\_reg,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{size\_pred,}\AttributeTok{y=}\NormalTok{time\_pred),}\AttributeTok{col=}\StringTok{"green"}\NormalTok{)}\SpecialCharTok{+}
\FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data=}\NormalTok{seq\_fct\_reg,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{size\_pred,}\AttributeTok{y=}\NormalTok{time\_pred),}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{)}\SpecialCharTok{+}
\FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data=}\NormalTok{builtin\_fct\_reg,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{size\_pred,}\AttributeTok{y=}\NormalTok{time\_pred),}\AttributeTok{col=}\StringTok{"red"}\NormalTok{)}\SpecialCharTok{+}
\FunctionTok{stat\_smooth}\NormalTok{(}\AttributeTok{method=}\StringTok{"lm"}\NormalTok{,}\AttributeTok{se=}\ConstantTok{FALSE}\NormalTok{)}\SpecialCharTok{+}
\FunctionTok{xlab}\NormalTok{(}\StringTok{"Size"}\NormalTok{)}\SpecialCharTok{+}
\FunctionTok{ylab}\NormalTok{(}\StringTok{"Time"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-36-1.pdf}

From the above plot we can see that the model predicts higher execution
times even for higher sizes for the parallel quick sort algorithm which
contradicts the result of the original experiment in which the parallel
had lower execution times for higher size values.

The model however does not really fit well the data for the parallel
data points. We can improve this model by removing the outliers, however
this is not the best solution as the experiment has a lot of flaws in
the first place such as having a big gap between the sizes tested and
the number of tests is still small, as well as the fact that the
experiments order between the different algorithms is always the same.
That's why we will design a new experiment.

\hypertarget{using-new-designed-experiment-results}{%
\subsection{Using new designed experiment
results}\label{using-new-designed-experiment-results}}

Here I design a new experiment that addresses the flaws of the previous
experiment. The improvements of this new experiment are:

\begin{itemize}
\tightlist
\item
  Random order of experiments between the different types
\item
  Random order of array sizes in when testing
\item
  Cover the whole space of values between 100 to 1000000
\item
  Increase the number of tests done
\end{itemize}

To do that we will use an lhs design to generate different sizes between
100 and 1000000, since this design is best for covering a space as much
as possible while not having a fixed spacing between the values, I
created the script \texttt{scripts/gen\_experiments.R} that generates
these experiment and this the resulting dataset:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{experiment }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\AttributeTok{file=}\StringTok{"data/experiments/qs\_experiment.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Check that we have same number of experiments for each type

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{experiment}\SpecialCharTok{$}\NormalTok{Type[experiment}\SpecialCharTok{$}\NormalTok{Type }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \StringTok{"Parallel"}
\NormalTok{experiment}\SpecialCharTok{$}\NormalTok{Type[experiment}\SpecialCharTok{$}\NormalTok{Type }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\OtherTok{\textless{}{-}} \StringTok{"Sequential"}
\NormalTok{experiment}\SpecialCharTok{$}\NormalTok{Type[experiment}\SpecialCharTok{$}\NormalTok{Type }\SpecialCharTok{==} \DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}} \StringTok{"Built{-}in"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{experiment }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{group\_by}\NormalTok{(Type) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{count}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
## # Groups:   Type [3]
##   Type           n
##   <chr>      <int>
## 1 Built-in     100
## 2 Parallel     100
## 3 Sequential   100
\end{verbatim}

To see this randomization better we do this plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{experiment}\SpecialCharTok{$}\NormalTok{order }\OtherTok{=}  \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{rownames}\NormalTok{(experiment))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}               
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ experiment, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Size, }\AttributeTok{y=}\NormalTok{order, }\AttributeTok{color =}\NormalTok{ Type))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-41-1.pdf}

We can see that the Size space is better covered and randomized, and the
order between the tests order is also well randomized.

I found that having 1000 for each type gives the best coverage of the
size space, however when I run these experiments they take so long on my
machine that's why I did this compromise of minimizing the number of
experiments so that I can have the results within reasonable time.

\hypertarget{new-experiment-analysis}{%
\subsection{New experiment analysis}\label{new-experiment-analysis}}

To run the generated experiments I use the script
\texttt{scripts/run\_experiments.sh} that puts the results of the
experiments in a csv file.

So let's analyse the results in this file:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{experiment\_results }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\AttributeTok{file=}\StringTok{"data/debian\_2023{-}02{-}03/measurements\_16:24.csv"}\NormalTok{)}
\NormalTok{experiment\_results}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Size       Type     Time
## 1   712551   Parallel 0.268414
## 2    95088   Parallel 0.060304
## 3   430781 Sequential 0.185050
## 4   500441   Parallel 0.185364
## 5   723611   Parallel 0.213794
## 6   693213   Parallel 0.192075
## 7   937829   Parallel 0.258711
## 8   991599   Built-in 0.312136
## 9   500441 Sequential 0.123389
## 10  813284 Sequential 0.211703
## 11  478853 Sequential 0.125772
## 12  705015 Sequential 0.166390
## 13  169946 Sequential 0.030899
## 14  632157   Built-in 0.152630
## 15  802915   Built-in 0.198373
## 16  145480   Built-in 0.030056
## 17  177833 Sequential 0.033977
## 18  902715 Sequential 0.204517
## 19   43834   Parallel 0.031603
## 20  117563   Parallel 0.043263
## 21  859621 Sequential 0.190664
## 22  946636 Sequential 0.212623
## 23  468381 Sequential 0.104282
## 24   33315 Sequential 0.006365
## 25  733191   Built-in 0.174122
## 26   73146 Sequential 0.016286
## 27  683534   Built-in 0.161024
## 28  101463   Parallel 0.040329
## 29  723611   Built-in 0.171675
## 30  457394   Built-in 0.102788
## 31  177833   Parallel 0.060401
## 32  885773   Built-in 0.217480
## 33  396346   Built-in 0.089399
## 34  427538   Parallel 0.126661
## 35  371716   Parallel 0.120689
## 36   43834 Sequential 0.012859
## 37   73146   Built-in 0.018172
## 38  833839   Built-in 0.218714
## 39  876829   Built-in 0.203447
## 40  512669   Parallel 0.151700
## 41  152995   Parallel 0.049659
## 42  306029   Parallel 0.092700
## 43  989248   Built-in 0.267757
## 44  427538   Built-in 0.095355
## 45  186039 Sequential 0.035696
## 46  885773 Sequential 0.199332
## 47  970988   Built-in 0.229626
## 48  924461   Built-in 0.218588
## 49  491520   Built-in 0.113037
## 50  705015   Parallel 0.199338
## 51  902715   Built-in 0.289401
## 52   57955   Built-in 0.016891
## 53  312722   Built-in 0.077841
## 54  967540   Built-in 0.300992
## 55  484994   Built-in 0.115087
## 56  989248   Parallel 0.283899
## 57  550375   Parallel 0.160782
## 58  733191 Sequential 0.235057
## 59  561942   Built-in 0.135106
## 60  457394   Parallel 0.139318
## 61  484994   Parallel 0.155345
## 62  208154   Built-in 0.044329
## 63  924461   Parallel 0.258116
## 64  328997   Parallel 0.102180
## 65  396346   Parallel 0.115677
## 66  885773   Parallel 0.255283
## 67  208154   Parallel 0.094914
## 68  937829   Built-in 0.355856
## 69  478853   Parallel 0.147159
## 70  478853   Built-in 0.135138
## 71  561942   Parallel 0.181474
## 72  338245 Sequential 0.114686
## 73  539638 Sequential 0.221575
## 74  101463 Sequential 0.021355
## 75   85073   Parallel 0.051549
## 76  813284   Parallel 0.232696
## 77  520039   Parallel 0.148051
## 78  443645   Built-in 0.107751
## 79  946636   Built-in 0.242015
## 80  859621   Built-in 0.236268
## 81  386723   Parallel 0.110194
## 82  604734 Sequential 0.124156
## 83  653117   Built-in 0.153968
## 84  254874 Sequential 0.048120
## 85   95088   Built-in 0.018193
## 86  653117 Sequential 0.140152
## 87  491520 Sequential 0.178369
## 88  443645   Parallel 0.130689
## 89  623686   Parallel 0.169028
## 90  234566   Parallel 0.071410
## 91  491520   Parallel 0.131355
## 92  712551 Sequential 0.197077
## 93  952322 Sequential 0.241011
## 94   62712   Built-in 0.019242
## 95  186039   Built-in 0.061035
## 96  589559   Parallel 0.181070
## 97  589559   Built-in 0.158406
## 98  520039 Sequential 0.168293
## 99  676884 Sequential 0.173140
## 100 263210   Parallel 0.087363
## 101 418075   Parallel 0.165485
## 102  12382   Parallel 0.055709
## 103 241825 Sequential 0.078990
## 104 668441   Built-in 0.159478
## 105 152995   Built-in 0.030825
## 106 579311 Sequential 0.158367
## 107 386723   Built-in 0.083377
## 108 131059 Sequential 0.024677
## 109 952322   Built-in 0.218148
## 110 306029 Sequential 0.064408
## 111  62712   Parallel 0.157505
## 112  12382 Sequential 0.002177
## 113 917312   Built-in 0.213638
## 114 970988 Sequential 0.282566
## 115 604734   Parallel 0.196484
## 116 579311   Built-in 0.202711
## 117 223338   Built-in 0.068866
## 118 693213   Built-in 0.173248
## 119 623686   Built-in 0.179318
## 120 124025 Sequential 0.033243
## 121 145480 Sequential 0.040763
## 122 186039   Parallel 0.078122
## 123 648621   Built-in 0.228665
## 124 290091   Parallel 0.104489
## 125 546513   Parallel 0.175344
## 126 780444   Built-in 0.184397
## 127  43834   Built-in 0.007951
## 128 484994 Sequential 0.114582
## 129 712551   Built-in 0.233751
## 130 408832   Parallel 0.120906
## 131 648621 Sequential 0.135116
## 132 290091   Built-in 0.064606
## 133    589   Built-in 0.000068
## 134 366408   Built-in 0.082383
## 135 338245   Built-in 0.073905
## 136 223338 Sequential 0.046655
## 137 457394 Sequential 0.094466
## 138 427538 Sequential 0.084871
## 139 145480   Parallel 0.050679
## 140  33315   Built-in 0.005998
## 141 396346 Sequential 0.078179
## 142 802915 Sequential 0.177375
## 143  20691   Built-in 0.003494
## 144  85073 Sequential 0.016098
## 145 924461 Sequential 0.194095
## 146 546513   Built-in 0.119685
## 147 828457 Sequential 0.185213
## 148 371716   Built-in 0.092158
## 149  95088 Sequential 0.022057
## 150 859621   Parallel 0.233907
## 151 970988   Parallel 0.275749
## 152 579311   Parallel 0.182872
## 153 828457   Built-in 0.211130
## 154 989248 Sequential 0.215506
## 155  85073   Built-in 0.016310
## 156 676884   Parallel 0.191865
## 157 813284   Built-in 0.196816
## 158 275367   Parallel 0.084795
## 159 733191   Parallel 0.201386
## 160 468381   Parallel 0.133354
## 161 328997   Built-in 0.073934
## 162 418075   Built-in 0.100445
## 163 288140   Built-in 0.063339
## 164 937829 Sequential 0.233821
## 165 197433 Sequential 0.036801
## 166 876829 Sequential 0.186522
## 167 117563 Sequential 0.021152
## 168 828457   Parallel 0.234912
## 169 169946   Built-in 0.045947
## 170 868601   Built-in 0.204766
## 171 610082   Parallel 0.174296
## 172 546513 Sequential 0.115050
## 173 366408 Sequential 0.074615
## 174 604734   Built-in 0.136243
## 175 500441   Built-in 0.113022
## 176 306029   Built-in 0.068711
## 177 794978   Parallel 0.234133
## 178 288140 Sequential 0.057536
## 179 290091 Sequential 0.064102
## 180 610082   Built-in 0.135355
## 181 598653   Built-in 0.140419
## 182 124025   Built-in 0.023646
## 183 348991   Built-in 0.073730
## 184 288140   Parallel 0.093506
## 185 776707   Parallel 0.224449
## 186 366408   Parallel 0.114549
## 187 312722 Sequential 0.061474
## 188 354183   Built-in 0.078720
## 189 312722   Parallel 0.093422
## 190 723611 Sequential 0.156951
## 191 843610   Built-in 0.198463
## 192 868601   Parallel 0.241083
## 193  20691 Sequential 0.003412
## 194 169946   Parallel 0.058262
## 195  12382   Built-in 0.002323
## 196 589559 Sequential 0.127285
## 197  62712 Sequential 0.010583
## 198 991599 Sequential 0.209768
## 199 776707   Built-in 0.176190
## 200 967540   Parallel 0.271547
## 201 833839 Sequential 0.170217
## 202 705015   Built-in 0.162453
## 203 952322   Parallel 0.239501
## 204 234566 Sequential 0.045084
## 205 550375 Sequential 0.112165
## 206 794978   Built-in 0.180695
## 207 348991   Parallel 0.108809
## 208 354183   Parallel 0.109247
## 209 254874   Parallel 0.084279
## 210 833839   Parallel 0.225280
## 211 991599   Parallel 0.274381
## 212 876829   Parallel 0.227262
## 213 780444   Parallel 0.210928
## 214 418075 Sequential 0.082142
## 215 117563   Built-in 0.024879
## 216 215356 Sequential 0.042696
## 217 223338   Parallel 0.076452
## 218 917312   Parallel 0.244560
## 219 241825   Built-in 0.065111
## 220 371716 Sequential 0.086900
## 221 780444 Sequential 0.164758
## 222 443645 Sequential 0.085758
## 223 550375   Built-in 0.124599
## 224 598653   Parallel 0.177568
## 225 946636   Parallel 0.258459
## 226 263210   Built-in 0.056642
## 227 177833   Built-in 0.036737
## 228 275367 Sequential 0.058326
## 229 683534   Parallel 0.199128
## 230 794978 Sequential 0.168541
## 231 152995 Sequential 0.028665
## 232 348991 Sequential 0.071487
## 233 408832 Sequential 0.106674
## 234 898868 Sequential 0.215255
## 235 215356   Built-in 0.043797
## 236 512669 Sequential 0.107861
## 237 668441   Parallel 0.186326
## 238 512669   Built-in 0.123374
## 239 263210 Sequential 0.060274
## 240  33315   Parallel 0.041408
## 241 124025   Parallel 0.048196
## 242 843610   Parallel 0.241429
## 243 756081   Built-in 0.187736
## 244 967540 Sequential 0.208793
## 245 776707 Sequential 0.165977
## 246 917312 Sequential 0.211659
## 247 539638   Parallel 0.150738
## 248 802915   Parallel 0.234986
## 249 843610 Sequential 0.198692
## 250 197433   Parallel 0.067951
## 251 653117   Parallel 0.193115
## 252 598653 Sequential 0.139714
## 253 898868   Built-in 0.237066
## 254  57955   Parallel 0.037697
## 255 430781   Built-in 0.105413
## 256 902715   Parallel 0.248847
## 257 632157 Sequential 0.133748
## 258 693213 Sequential 0.159932
## 259 215356   Parallel 0.070109
## 260 561942 Sequential 0.112697
## 261    589   Parallel 0.010177
## 262 648621   Parallel 0.190040
## 263 623686 Sequential 0.142987
## 264 868601 Sequential 0.213748
## 265 241825   Parallel 0.069857
## 266 740075 Sequential 0.151596
## 267 668441 Sequential 0.159709
## 268 740075   Parallel 0.214463
## 269  20691   Parallel 0.052264
## 270 328997 Sequential 0.078382
## 271 676884   Built-in 0.164212
## 272 468381   Built-in 0.106349
## 273 764505   Built-in 0.177027
## 274 208154 Sequential 0.038747
## 275 275367   Built-in 0.059983
## 276 101463   Built-in 0.019515
## 277 430781   Parallel 0.120534
## 278 610082 Sequential 0.140021
## 279 632157   Parallel 0.175420
## 280 354183 Sequential 0.081121
## 281  73146   Parallel 0.043984
## 282 764505   Parallel 0.217467
## 283 131059   Built-in 0.027775
## 284 254874   Built-in 0.067335
## 285 234566   Built-in 0.050145
## 286 338245   Parallel 0.103102
## 287 764505 Sequential 0.172818
## 288 898868   Parallel 0.246266
## 289    589 Sequential 0.000080
## 290 539638   Built-in 0.147750
## 291 197433   Built-in 0.050081
## 292 408832   Built-in 0.092833
## 293 683534 Sequential 0.153746
## 294 131059   Parallel 0.054307
## 295 756081   Parallel 0.221731
## 296 386723 Sequential 0.080152
## 297 520039   Built-in 0.127008
## 298  57955 Sequential 0.009881
## 299 740075   Built-in 0.185878
## 300 756081 Sequential 0.180740
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}               
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ experiment\_results, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Size, }\AttributeTok{y=}\NormalTok{Time, }\AttributeTok{color =}\NormalTok{ Type))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-43-1.pdf}

This result is much better as we can see there's much less interpolation
of the measurements and so more accurate evolutions of the measurements,
as we can see there some outliers in which the time measurement is very
high which could be due to a huge load on the machine at that time.

So to mitigate this, like we did in the previous experiment we will use
measurements from different times:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{local\_results }\OtherTok{\textless{}{-}} \FunctionTok{list.files}\NormalTok{(}\AttributeTok{path =} \StringTok{"./data/debian\_2023{-}02{-}03/"}\NormalTok{, }\AttributeTok{pattern =} \StringTok{"*.csv"}\NormalTok{, }\AttributeTok{full.names =}\NormalTok{ T) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{map\_df}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{read\_csv}\NormalTok{(.)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 300 Columns: 3-- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): Type
## dbl (2): Size, Time
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.Rows: 300 Columns: 3-- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): Type
## dbl (2): Size, Time
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.Rows: 300 Columns: 3-- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): Type
## dbl (2): Size, Time
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dplyr}\SpecialCharTok{::}\FunctionTok{glimpse}\NormalTok{(local\_results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 900
## Columns: 3
## $ Size <dbl> 712551, 95088, 430781, 500441, 723611, 693213, 937829, 991599, 50~
## $ Type <chr> "Parallel", "Parallel", "Sequential", "Parallel", "Parallel", "Pa~
## $ Time <dbl> 0.268414, 0.060304, 0.185050, 0.185364, 0.213794, 0.192075, 0.258~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{local\_results}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 900 x 3
##      Size Type         Time
##     <dbl> <chr>       <dbl>
##  1 712551 Parallel   0.268 
##  2  95088 Parallel   0.0603
##  3 430781 Sequential 0.185 
##  4 500441 Parallel   0.185 
##  5 723611 Parallel   0.214 
##  6 693213 Parallel   0.192 
##  7 937829 Parallel   0.259 
##  8 991599 Built-in   0.312 
##  9 500441 Sequential 0.123 
## 10 813284 Sequential 0.212 
## # ... with 890 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}               
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ local\_results, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Size, }\AttributeTok{y=}\NormalTok{Time, }\AttributeTok{color =}\NormalTok{ Type))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-45-1.pdf}

We can see that we have less fluctuations than the previous graph, to
improve this we should increase the time interval between generated
measurements.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{local\_results}\SpecialCharTok{$}\NormalTok{Type\_F }\OtherTok{=} \FunctionTok{as.factor}\NormalTok{(local\_results}\SpecialCharTok{$}\NormalTok{Type)}
\FunctionTok{with}\NormalTok{(local\_results, }\FunctionTok{plot}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Type\_F))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-46-1.pdf}

We can see that we have big confidence intervals, and that's expected as
the execution time for each algorithm changes with the size.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mandelbrot\_results }\OtherTok{\textless{}{-}} \FunctionTok{list.files}\NormalTok{(}\AttributeTok{path =} \StringTok{"./data/im2ag{-}mandelbrot\_2023{-}02{-}03/"}\NormalTok{, }\AttributeTok{pattern =} \StringTok{"*.csv"}\NormalTok{, }\AttributeTok{full.names =}\NormalTok{ T) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{map\_df}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{read\_csv}\NormalTok{(.)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 300 Columns: 3-- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): Type
## dbl (2): Size, Time
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.Rows: 300 Columns: 3-- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): Type
## dbl (2): Size, Time
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.Rows: 300 Columns: 3-- Column specification --------------------------------------------------------
## Delimiter: ","
## chr (1): Type
## dbl (2): Size, Time
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dplyr}\SpecialCharTok{::}\FunctionTok{glimpse}\NormalTok{(mandelbrot\_results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 900
## Columns: 3
## $ Size <dbl> 712551, 95088, 430781, 500441, 723611, 693213, 937829, 991599, 50~
## $ Type <chr> "Parallel", "Parallel", "Sequential", "Parallel", "Parallel", "Pa~
## $ Time <dbl> 0.349309, 0.270634, 0.101248, 0.260798, 0.376618, 0.396751, 0.471~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mandelbrot\_results}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 900 x 3
##      Size Type        Time
##     <dbl> <chr>      <dbl>
##  1 712551 Parallel   0.349
##  2  95088 Parallel   0.271
##  3 430781 Sequential 0.101
##  4 500441 Parallel   0.261
##  5 723611 Parallel   0.377
##  6 693213 Parallel   0.397
##  7 937829 Parallel   0.472
##  8 991599 Built-in   0.267
##  9 500441 Sequential 0.116
## 10 813284 Sequential 0.198
## # ... with 890 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}               
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ mandelbrot\_results, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Size, }\AttributeTok{y=}\NormalTok{Time, }\AttributeTok{color =}\NormalTok{ Type))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-48-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mandelbrot\_results}\SpecialCharTok{$}\NormalTok{Type\_F }\OtherTok{=} \FunctionTok{as.factor}\NormalTok{(mandelbrot\_results}\SpecialCharTok{$}\NormalTok{Type)}
\FunctionTok{with}\NormalTok{(mandelbrot\_results, }\FunctionTok{plot}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Type\_F))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-49-1.pdf}

Here again we have big execution times for the parallel algorithm in
this machine, ideally we should check this in another machine since we
have a big difference between the parallel execution time between the
two machines, but for now I will continue the analysis we these results
since for now I do not have acces to another machine.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merged\_results }\OtherTok{=} \FunctionTok{union}\NormalTok{(local\_results, mandelbrot\_results)}
\NormalTok{dplyr}\SpecialCharTok{::}\FunctionTok{glimpse}\NormalTok{(merged\_results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 1,800
## Columns: 4
## $ Size   <dbl> 712551, 95088, 430781, 500441, 723611, 693213, 937829, 991599, ~
## $ Type   <chr> "Parallel", "Parallel", "Sequential", "Parallel", "Parallel", "~
## $ Time   <dbl> 0.268414, 0.060304, 0.185050, 0.185364, 0.213794, 0.192075, 0.2~
## $ Type_F <fct> Parallel, Parallel, Sequential, Parallel, Parallel, Parallel, P~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merged\_results}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1,800 x 4
##      Size Type         Time Type_F    
##     <dbl> <chr>       <dbl> <fct>     
##  1 712551 Parallel   0.268  Parallel  
##  2  95088 Parallel   0.0603 Parallel  
##  3 430781 Sequential 0.185  Sequential
##  4 500441 Parallel   0.185  Parallel  
##  5 723611 Parallel   0.214  Parallel  
##  6 693213 Parallel   0.192  Parallel  
##  7 937829 Parallel   0.259  Parallel  
##  8 991599 Built-in   0.312  Built-in  
##  9 500441 Sequential 0.123  Sequential
## 10 813284 Sequential 0.212  Sequential
## # ... with 1,790 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}               
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data =}\NormalTok{ merged\_results, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Size, }\AttributeTok{y=}\NormalTok{Time, }\AttributeTok{color =}\NormalTok{ Type))}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-51-1.pdf}

As expected the big difference in parallel execution times between the
machines results in having a lot of flectuations in the parallel
algorithm graph, which will make it more difficult for the model to fit
values for the parallel type.

Let's try to fit a model with this data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg\_test\_results }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Time }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{data =}\NormalTok{ merged\_results)}
\FunctionTok{step}\NormalTok{(reg\_test\_results, }\AttributeTok{scope=}\NormalTok{Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size}\SpecialCharTok{+}\NormalTok{Type\_F, }\AttributeTok{direction=}\StringTok{"forward"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Start:  AIC=-7946.82
## Time ~ 1
## 
##          Df Sum of Sq    RSS     AIC
## + Size    1    9.5554 12.193 -8986.5
## + Type_F  2    6.0353 15.713 -8527.9
## <none>                21.748 -7946.8
## 
## Step:  AIC=-8986.46
## Time ~ Size
## 
##          Df Sum of Sq     RSS      AIC
## + Type_F  2    6.0353  6.1575 -10212.2
## <none>                12.1927  -8986.5
## 
## Step:  AIC=-10212.18
## Time ~ Size + Type_F
\end{verbatim}

\begin{verbatim}
## 
## Call:
## lm.default(formula = Time ~ Size + Type_F, data = merged_results)
## 
## Coefficients:
##      (Intercept)              Size    Type_FParallel  Type_FSequential  
##       -2.072e-04         2.522e-07         1.178e-01        -9.494e-03
\end{verbatim}

So the best model is the one that has both type and size in it, which is
right.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{reg\_results }\OtherTok{=} \FunctionTok{lm}\NormalTok{(Time}\SpecialCharTok{\textasciitilde{}}\NormalTok{Size}\SpecialCharTok{+}\NormalTok{Type\_F, }\AttributeTok{data=}\NormalTok{merged\_results)}
\FunctionTok{summary}\NormalTok{(reg\_results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm.default(formula = Time ~ Size + Type_F, data = merged_results)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.118275 -0.015426  0.000596  0.010356  0.261098 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(>|t|)    
## (Intercept)      -2.072e-04  3.379e-03  -0.061  0.95112    
## Size              2.522e-07  4.777e-09  52.793  < 2e-16 ***
## Type_FParallel    1.178e-01  3.381e-03  34.850  < 2e-16 ***
## Type_FSequential -9.494e-03  3.381e-03  -2.809  0.00503 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.05855 on 1796 degrees of freedom
## Multiple R-squared:  0.7169, Adjusted R-squared:  0.7164 
## F-statistic:  1516 on 3 and 1796 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(reg\_results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Response: Time
##             Df Sum Sq Mean Sq F value    Pr(>F)    
## Size         1 9.5554  9.5554 2787.11 < 2.2e-16 ***
## Type_F       2 6.0353  3.0176  880.18 < 2.2e-16 ***
## Residuals 1796 6.1575  0.0034                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

The R squared is worse than the one from previous experiment, this could
probably be due to having more data in this experiment. The residual
standard error is still small which is good, and the F statistic is
higher as now the model gives more importance to the sequential type
feature as opposed to the previous model, however the intercept is not
considered important and this could be due to the fact that the
execution times of both the sequential and built-in are very similar so
the model can explain the variability of the built-in type with the
sequential type.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred }\OtherTok{=} \FunctionTok{predict}\NormalTok{(reg\_results, }\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Size=}\DecValTok{300000}\NormalTok{, }\AttributeTok{Type\_F=}\StringTok{"Parallel"}\NormalTok{),}\AttributeTok{interval=}\StringTok{"prediction"}\NormalTok{)}
\NormalTok{pred}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         fit        lwr       upr
## 1 0.1932631 0.07831349 0.3082128
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results\_confidence }\OtherTok{=} \FloatTok{0.3082128{-}0.07831349}
\NormalTok{results\_confidence}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2298993
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merged\_confidence}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2054555
\end{verbatim}

Although we used more data to fit this model we still got similar
confidence interval than the previous model which could be explained by
a high variability of this data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfcol=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(reg\_results)}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-57-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(reg\_results, }\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-57-2.pdf}

The Residuals vs fitted plots are much better than the ones in the
previous model as we can see we the residuals do not have a particular
structure and they are evenly distributed over the x-axis, the cook's
distance plot is also better as most points are clustered in one region
except some few outliers that are far. However the Normal Q-Q plot is
worse as a lot of residuals are not normally distributed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{size\_pred }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{100}\NormalTok{,}\DecValTok{1000000}\NormalTok{,}\AttributeTok{by=}\DecValTok{5000}\NormalTok{)}
\NormalTok{type\_pred }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{), }\FunctionTok{length}\NormalTok{(size\_pred))}

\NormalTok{par\_time\_pred }\OtherTok{\textless{}{-}}\NormalTok{ reg\_merged}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{+}\NormalTok{reg\_results}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{2}\NormalTok{]}\SpecialCharTok{*}\NormalTok{size\_pred}\SpecialCharTok{+}\NormalTok{reg\_results}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{3}\NormalTok{]}
\NormalTok{seq\_time\_pred }\OtherTok{\textless{}{-}}\NormalTok{ reg\_merged}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{+}\NormalTok{reg\_results}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{2}\NormalTok{]}\SpecialCharTok{*}\NormalTok{size\_pred}\SpecialCharTok{+}\NormalTok{reg\_results}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{4}\NormalTok{]}
\NormalTok{builtin\_time\_pred }\OtherTok{\textless{}{-}}\NormalTok{ reg\_merged}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{+}\NormalTok{reg\_results}\SpecialCharTok{$}\NormalTok{coefficients[}\DecValTok{2}\NormalTok{]}\SpecialCharTok{*}\NormalTok{size\_pred}

\NormalTok{par\_fct\_reg }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{size\_pred=}\NormalTok{size\_pred, }\AttributeTok{time\_pred=}\NormalTok{par\_time\_pred)}
\NormalTok{seq\_fct\_reg }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{size\_pred=}\NormalTok{size\_pred, }\AttributeTok{type\_pred=}\NormalTok{type\_pred, }\AttributeTok{time\_pred=}\NormalTok{seq\_time\_pred)}
\NormalTok{builtin\_fct\_reg }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{size\_pred=}\NormalTok{size\_pred, }\AttributeTok{type\_pred=}\NormalTok{type\_pred, }\AttributeTok{time\_pred=}\NormalTok{builtin\_time\_pred)}

\FunctionTok{ggplot}\NormalTok{()}\SpecialCharTok{+}
\FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data=}\NormalTok{merged\_results,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Size,}\AttributeTok{y=}\NormalTok{Time, }\AttributeTok{color =}\NormalTok{ Type))}\SpecialCharTok{+} \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data=}\NormalTok{par\_fct\_reg,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{size\_pred,}\AttributeTok{y=}\NormalTok{time\_pred),}\AttributeTok{col=}\StringTok{"green"}\NormalTok{)}\SpecialCharTok{+}
\FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data=}\NormalTok{seq\_fct\_reg,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{size\_pred,}\AttributeTok{y=}\NormalTok{time\_pred),}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{)}\SpecialCharTok{+}
\FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{data=}\NormalTok{builtin\_fct\_reg,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{size\_pred,}\AttributeTok{y=}\NormalTok{time\_pred),}\AttributeTok{col=}\StringTok{"red"}\NormalTok{)}\SpecialCharTok{+}
\FunctionTok{stat\_smooth}\NormalTok{(}\AttributeTok{method=}\StringTok{"lm"}\NormalTok{,}\AttributeTok{se=}\ConstantTok{FALSE}\NormalTok{)}\SpecialCharTok{+}
\FunctionTok{xlab}\NormalTok{(}\StringTok{"Size"}\NormalTok{)}\SpecialCharTok{+}
\FunctionTok{ylab}\NormalTok{(}\StringTok{"Time"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{quickSort_files/figure-latex/unnamed-chunk-58-1.pdf}

We can see that the model does fit well the sequential and built-in
types, however for the parallel type the fit is bad which gives higher
errors in the parallel type which explains why the residuals are not
normally distributed since the residuals of parallel type will be so
different from those of the other types so they are the outliers that
causes the residuals to not be normally distributed.

To fix this we should run our experiment on some other machines and
compare with the results of the machines we used here to see which one
is the outlier to discard.

\end{document}
